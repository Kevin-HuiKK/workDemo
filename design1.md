

### 方案概述

本方案旨在实现基于AWS Lambda的实时语音识别、翻译和语音合成系统，以处理前端实时传输的音频流。每个文本短句经过实时处理后直接输出流给客户端，避免了Lambda输出大小限制，并通过负载动态调整语音合成的速度，保持系统的实时性和响应速度。
1. **音频捕获与分段**：前端定期捕获音频，并根据定时器和静音检测进行分段，避免单次处理超过AWS Lambda的最大执行时间。
2. **音频流处理**：每个音频段发送到AWS Lambda进行处理。Lambda函数调用Transcribe进行语音识别，并实时处理生成的文本，进行断句标识判断。
3. **文本传递**：检测到句子结束标点后，将当前段落通过SNS发送给另一个Lambda函数。
4. **SNS队列监控与自动加速**：TTS-Lambda函数根据SNS队列积压情况调整播放速度，以确保及时播放音频。
5. **文本翻译与语音合成**：TTS-Lambda函数接收到SNS消息后，进行翻译并调用Polly生成音频，直接返回给前端。

### 技术难点分析

1. **Lambda执行时间限制**：
   - Lambda连续运行时间要求不超过15分钟
   - 需要前端进行在超过一定时间后开启静音检测分段，分段后交给使用AWS Transcribe进行Stream实时语音识别，确保每段音频在Lambda的执行时间限制内完成处理
   - 对于rtc链接超过15分钟的情况需要单独测试，可以尝试超时重连验证；或者改用EC2来支持。

2. **实时流处理**：
   - 每个音频段发送到AWS Lambda1进行处理。
   - 利用AWS的流式翻译功能，并实时处理生成的文本。根据增量检测到句子结束标点时，通过SNS发送给另一个Lambda2函数。

3. **Lambda输出大小限制**：
   - Lambda函数的输出限制为8MB，需要提前分句，使每个文本短句对应一个流，避免输出限制问题。
   - 可选的使用S3转存，增加了延迟，仅做备选方案。

4. **语速控制**：
   - 如果说话者语速远高于接受者播放语速，会出现严重偏离。
   - 利用AWS Polly的语音合成速度控制功能，根据系统负载（SNS队列深度）动态调整语音合成的速度，保持语音的自然流畅性。

5. **断句策略调测**：
    - 选择适合的断句标志，如逗号、句号等，以及其他语言特定的断句规则，以提高实时性和处理效率。
    - 增量式处理：考虑使用增量式处理方法，即在音频流中逐步增加文本内容并实时发送给翻译模块，而不是等待整句完成再处理。这种方法可以提高处理速度和实时性。

5. **翻译质量问题**：
   - 对于原始语言为汉语等翻译效果较差的情况，可能需要考虑其他服务。
   - 
![image](https://github.com/user-attachments/assets/66ccd37d-f105-42ed-82d7-b04257ea640c)

通过以上技术难点的分析和方案概述，可以有效地设计和实现一个高效、稳定的实时语音处理系统，满足实时性要求并克服AWS Lambda的限制。
### 设计图纸
 ![image](https://github.com/user-attachments/assets/7f603207-c4eb-4960-bbeb-4fe09f818deb)

### 模块说明

#### M1. 前端音频捕捉与处理模块

- **功能说明**：
  - 前端使用WebRTC捕捉实时音频流。
  - 根据需要考虑降噪
  - 静音检测，对音频流进行分段，以确保每段音频长度适合AWS Lambda的最大执行时间限制。
  - 将分段后的音频流通过WebSocket传输给AWS Lambda1。

#### M2. AWS Lambda1: Transcribe 模块

- **功能说明**：
  - Lambda函数接收前端通过WebSocket传输的音频流。
  - 设定语言种类，使用AWS Transcribe服务进行实时语音识别。
  - 当识别到句子结束标点时，将文本段落发送到SNS队列，通知AWS Lambda2模块处理。

#### M3. 消息通知模块: SNS

- **功能说明**：
  - AWS SNS（Simple Notification Service）用于消息的发布和订阅。
  - AWS Lambda1: Transcribe模块在识别完成并分段后，通过SNS将识别结果发送给AWS Lambda2: Synthesize模块。

#### M4. AWS Lambda2: Synthesize 模块

- **功能说明**：
  - Lambda函数订阅SNS消息，接收对应的文本段落。
  - 使用AWS Translate服务进行翻译。
  - 使用AWS Polly服务进行实时语音合成，生成音频流。
  - 将生成的音频流通过WebSocket直接传输给前端，实现实时的语音合成和播放。

对不起，前面的消息被我忽略了。这里是对M5的补充：

#### M5. 用户2 - WebRTC音频接收与播放模块
- **功能说明**：
  - 功能说明： 用户2通过WebRTC接收从后端（例如Lambda2）发送的实时音频流。
  - 实现方式： 前端利用WebRTC建立连接，接收Lambda2实时发送的音频流。
  - 播放处理：前端使用Web Audio API或其他音频处理库，播放接收到的音频流。
  - 协作方式：Lambda2负责根据收到的SNS消息进行翻译和语音合成，并即时发送音频流给用户2。用户2与Lambda2之间通过WebRTC连接，实现实时音频的接收和播放。

### 方案评估
由于lambda的诸多限制，以及aws的三次转换服务造成的等待时间延迟，目前评估该方案风险较高。

